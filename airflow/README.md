# GuÃ­a de Inicio RÃ¡pido: Apache Airflow

Esta guÃ­a te ayudarÃ¡ a configurar y ejecutar Apache Airflow para observar tu pipeline Kafka â†’ MongoDB.

## ğŸš€ Inicio RÃ¡pido

### 1. Levantar Airflow con Docker

```bash
docker-compose -f docker-compose-airflow.yml up -d
```

**Â¡Listo!** Este comando:
- âœ… Levanta todos los contenedores de Airflow
- âœ… Crea automÃ¡ticamente el usuario `admin`
- âœ… Genera una contraseÃ±a segura

### Obtener la contraseÃ±a

Espera ~1 minuto y ejecuta:

```bash
docker logs airflow-webserver 2>&1 | grep -i password
```

VerÃ¡s algo como:
```
Simple auth manager | Password for user 'admin': "PASSWORD_AIRFLOW"
```

### Acceder a Airflow

**URL:** http://localhost:8080
- Usuario: `admin`
- Password: La que obtuviste arriba


---

## ğŸ›‘ Comandos Ãštiles

**Detener Airflow (mantiene password):**
```bash
docker-compose -f docker-compose-airflow.yml down
```

**Detener y borrar todo (regenera password):**
```bash
docker-compose -f docker-compose-airflow.yml down -v
```

**Ver logs:**
```bash
docker logs -f airflow-webserver   # Webserver
docker logs -f airflow-scheduler   # Scheduler
```

---

3. **Abrir WSL2** y seguir las instrucciones de instalaciÃ³n local

## ğŸ“Š Usar el DAG de ObservaciÃ³n

### Activar el DAG

1. En la UI de Airflow, busca el DAG: `kafka_mongodb_health_monitor`
2. Activa el toggle (debe ponerse en azul/verde)
3. El DAG se ejecutarÃ¡ automÃ¡ticamente cada 10 minutos
## ğŸ“Š Usar el DAG de Monitoreo

### 1. Activar el DAG

1. En la UI de Airflow, busca: `kafka_mongodb_health_monitor`
2. Activa el toggle (se pone azul/verde)
3. Se ejecutarÃ¡ automÃ¡ticamente cada 10 minutos

### 2. Ejecutar Manualmente (Testing)

1. Click en el nombre del DAG
2. Click en "â–¶ï¸ Trigger DAG"
3. Click en "Trigger"

### 3. Ver Logs

Click en la tarea `generate_health_summary` â†’ "Log"

VerÃ¡s algo como:
```
ğŸ“Š RESUMEN DE SALUD DEL PIPELINE KAFKA â†’ MongoDB
ğŸš¦ Estado General: HEALTHY
ğŸ“¦ Total documentos: 5247
ğŸ• Ãšltima inserciÃ³n: 0:00:12
ğŸ“ˆ Tasa inserciÃ³n: 45.20 docs/min
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Cambiar frecuencia de monitoreo

Edita `airflow/dags/kafka_mongodb_observer.py`:

```python
schedule_interval='*/10 * * * *',  # Cada 10 minutos
```

Ejemplos:
- `'*/5 * * * *'` = Cada 5 minutos
- `'0 * * * *'` = Cada hora

### Cambiar base de datos MongoDB

Edita la variable de entorno en `.env`:
```bash
MONGO_ATLAS_URI=mongodb+srv://user:pass@cluster.mongodb.net/
```

---

## ğŸ› Troubleshooting

**El DAG no aparece:**
- Espera 30 segundos (Airflow escanea cada 30s)
- Verifica: `docker logs airflow-scheduler`

**Error de conexiÃ³n a MongoDB:**
- Verifica tu `MONGO_ATLAS_URI` en `.env`
- AsegÃºrate que la IP estÃ¡ en whitelist de MongoDB Atlas

**Ver logs completos:**
```bash
docker logs -f airflow-scheduler
```

---
```bash
airflow db reset
```

**Listar DAGs:**
```bash
airflow dags list
---

## ğŸ“š Recursos

- [DocumentaciÃ³n Airflow 3.0](https://airflow.apache.org/docs/apache-airflow/stable/)
- [Cron Expression Generator](https://crontab.guru/)

